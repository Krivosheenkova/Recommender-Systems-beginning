{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# #5 Ranking and Hybrid Recommender Systems"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Построение длинного и короткого портфеля акций с помощью\n",
    "нового алгоритма listwise learn-to-ranking](https://arxiv.org/pdf/2104.12484.pdf)_(pdf)_\n",
    "\n",
    "[Recommender system using Bayesian personalized ranking](https://towardsdatascience.com/recommender-system-using-bayesian-personalized-ranking-d30e98bba0b9)_(towardsdatascience)_\n",
    "\n",
    "[Intro to WARP Loss, automatic differentiation and PyTorch](https://medium.com/@gabrieltseng/intro-to-warp-loss-automatic-differentiation-and-pytorch-b6aa5083187a)_(towardsdatascience)_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!conda install lightfm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.utils import prefilter_items\n",
    "print('Done')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "data = pd.read_csv('../../retail_train.csv')\n",
    "\n",
    "item_features = pd.read_csv('../../product.csv')\n",
    "user_features = pd.read_csv('../../hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# prefilter data\n",
    "print('Train Sample')\n",
    "data_train_filtered = prefilter_items(data_train, take_n_popular=5000, item_features=item_features)\n",
    "print()\n",
    "print('Test Sample')\n",
    "data_test_filtered = prefilter_items(data_test, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "\n",
    "# prepare CSR train data\n",
    "user_item_matrix = pd.pivot_table(data_train_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', \n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 ).astype(float) \n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "\n",
    "# prepare CSR test data\n",
    "data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "test_user_item_matrix = pd.pivot_table(data_test_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity',\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float)\n",
    "\n",
    "\n",
    "# prepare dicts\n",
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "\n",
    "# prepare user/items features\n",
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "\n",
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "\n",
    "# encoding features\n",
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Sample\n",
      "== Starting prefilter info ==\n",
      "shape: (2278490, 12)\n",
      "# users: 2499\n",
      "# items: 86865\n",
      "Sparsity: 1.050%\n",
      "== Ending prefilter info ==\n",
      "shape: (1060465, 12)\n",
      "# users: 2459\n",
      "# items: 5000\n",
      "Sparsity: 8.625%\n",
      "\n",
      "Test Sample\n",
      "== Starting prefilter info ==\n",
      "shape: (118314, 12)\n",
      "# users: 2042\n",
      "# items: 24329\n",
      "Sparsity: 0.238%\n",
      "== Ending prefilter info ==\n",
      "shape: (66494, 12)\n",
      "# users: 1905\n",
      "# items: 5000\n",
      "Sparsity: 0.698%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Grid Search with **hyperopt***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# !pip install hyperopt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "model.get_params()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'loss': 'warp',\n",
       " 'learning_schedule': 'adagrad',\n",
       " 'no_components': 40,\n",
       " 'learning_rate': 0.05,\n",
       " 'k': 5,\n",
       " 'n': 10,\n",
       " 'rho': 0.95,\n",
       " 'epsilon': 1e-06,\n",
       " 'max_sampled': 10,\n",
       " 'item_alpha': 0.1,\n",
       " 'user_alpha': 0.1,\n",
       " 'random_state': RandomState(MT19937) at 0x7FC8E8B74E40}"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "def evaluate_model(model, filtered_data, user_features, item_features) -> float:\n",
    "    user_item_matrix = pd.pivot_table(\n",
    "        filtered_data, \n",
    "        index='user_id', columns='item_id', \n",
    "        values='quantity',\n",
    "        aggfunc='count', \n",
    "        fill_value=0\n",
    "    ).astype(float)\n",
    "    sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "    user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "    user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "    user_feat.set_index('user_id', inplace=True)\n",
    "    item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "    item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "    item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "    user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "    item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())\n",
    "\n",
    "    model.fit(\n",
    "          (sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4,# A sum of an array that contains non-finite values\n",
    "            # will also be non-finite, and we avoid creating a\n",
    "            # large boolean temporary.\n",
    "          verbose=False\n",
    "          )\n",
    "\n",
    "    p = precision_at_k(\n",
    "        model, \n",
    "        sparse_user_item, \n",
    "        user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "        item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "        k=5).mean()\n",
    "\n",
    "    return p, model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "from hyperopt import hp, Trials, fmin, tpe, STATUS_OK\n",
    "from math import e\n",
    "\n",
    "def hyperopt_obj(params, data):\n",
    "    t = params['type']\n",
    "    del params['type']\n",
    "    if t == 'lightfm':\n",
    "        clf = LightFM(**params)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    return evaluate_model(model=clf, \n",
    "                          filtered_data=data,\n",
    "                          user_features=user_features,\n",
    "                          item_features=item_features)\n",
    "\n",
    "space = hp.choice('task', \n",
    "    [\n",
    "        {'type': 'lightfm',\n",
    "         'loss': hp.choice('loss', ['warp', 'bpr']),\n",
    "         'no_components': hp.choice('n_components', range(40, 150)),\n",
    "         'learning_rate': hp.choice('learning_rate', [.005, .01, .1, .15,]),\n",
    "         'max_sampled': hp.choice('max_sampled', range(5, 16)),\n",
    "         'epsilon': hp.uniform('epsilon', 1e-6, 1e-2),\n",
    "         'item_alpha': hp.uniform('item_alpha', 1e-3, 0.1),\n",
    "         'user_alpha': hp.uniform('user_alpha', 1e-3, 0.1),\n",
    "         'random_state': hp.choice('random_state', [111])}\n",
    "    ])\n",
    "\n",
    "count = 0\n",
    "best = 0\n",
    "def f(params):\n",
    "    global best, count\n",
    "    count += 1\n",
    "    acc, model = hyperopt_obj(params.copy(), data_train_filtered)\n",
    "    acc_test = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "    if acc > best:\n",
    "        print('new best:', acc, 'using', params['type'], sep=' ')\n",
    "        best = acc\n",
    "    if count % 50 == 0:\n",
    "        print('iters:', count, ', acc:', acc, 'using', params, sep=' ')\n",
    "    return {'loss': -acc, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(f, space, algo=tpe.suggest, max_evals=200, trials=trials)\n",
    "print(f'best:\\n{best}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "new best:\n",
      "0.14485563\n",
      "using\n",
      "lightfm\n",
      "new best:\n",
      "0.30467674\n",
      "using\n",
      "lightfm\n",
      "new best:\n",
      "0.35290772\n",
      "using\n",
      "lightfm\n",
      "new best:\n",
      "0.3536397\n",
      "using\n",
      "lightfm\n",
      "iters:\n",
      "50\n",
      ", acc:\n",
      "0.347621\n",
      "using\n",
      "{'epsilon': 0.00042298141597467333, 'item_alpha': 0.00948529229349785, 'learning_rate': 0.1, 'loss': 'warp', 'max_sampled': 12, 'no_components': 133, 'random_state': 111, 'type': 'lightfm', 'user_alpha': 0.039538871217095393}\n",
      "new best:\n",
      "0.36445713\n",
      "using\n",
      "lightfm\n",
      "iters:\n",
      "100\n",
      ", acc:\n",
      "0.36445713\n",
      "using\n",
      "{'epsilon': 0.001081398222679707, 'item_alpha': 0.07624550897302623, 'learning_rate': 0.005, 'loss': 'warp', 'max_sampled': 8, 'no_components': 118, 'random_state': 111, 'type': 'lightfm', 'user_alpha': 0.024828070837681973}\n",
      "new best:\n",
      "0.37259048\n",
      "using\n",
      "lightfm\n",
      "iters:\n",
      "150\n",
      ", acc:\n",
      "0.26116312\n",
      "using\n",
      "{'epsilon': 0.0007773693800380998, 'item_alpha': 0.0787134782645475, 'learning_rate': 0.005, 'loss': 'warp', 'max_sampled': 8, 'no_components': 76, 'random_state': 111, 'type': 'lightfm', 'user_alpha': 0.027743744179105925}\n",
      "iters:\n",
      "200\n",
      ", acc:\n",
      "0.200488\n",
      "using\n",
      "{'epsilon': 0.0011206811216958146, 'item_alpha': 0.07983765012392162, 'learning_rate': 0.005, 'loss': 'warp', 'max_sampled': 12, 'no_components': 44, 'random_state': 111, 'type': 'lightfm', 'user_alpha': 0.04263323414053811}\n",
      "100%|██████████| 200/200 [11:07:21<00:00, 200.21s/trial, best loss: -0.37259048223495483]\n",
      "best:\n",
      "{'epsilon': 0.002069049036324821, 'item_alpha': 0.08740694774900581, 'learning_rate': 0, 'loss': 0, 'max_sampled': 8, 'n_components': 58, 'random_state': 0, 'task': 0, 'user_alpha': 0.014618091253110099}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "best = {'epsilon': 0.0011206811216958146, \n",
    "        'item_alpha': 0.07983765012392162, \n",
    "        'learning_rate': 0.005, \n",
    "        'loss': 'warp', \n",
    "        'max_sampled': 12, \n",
    "        'no_components': 44, \n",
    "        'random_state': 111, \n",
    "        'type': 'lightfm', \n",
    "        'user_alpha': 0.04263323414053811}\n",
    "        \n",
    "del best['type']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Init model*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "model = LightFM(**best)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Fit Train*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "%%time\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4,\n",
    "          verbose=False) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 4min 9s, sys: 1.85 s, total: 4min 11s\n",
      "Wall time: 1min 20s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fc8d9af6b80>"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Evaluation*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "user_emb = model.get_user_representations(features=csr_matrix(user_feat_lightfm.values).tocsr())\n",
    "item_emb = model.get_item_representations(features=csr_matrix(item_feat_lightfm.values).tocsr())\n",
    "\n",
    "print('user_emb shapes:', user_emb[0].shape, user_emb[1].shape)\n",
    "print('item_emb shapes:', item_emb[0].shape, item_emb[1].shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "user_emb shapes: (2459,) (2459, 44)\n",
      "item_emb shapes: (5000,) (5000, 44)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Train Precision*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "%%time\n",
    "train_precision = precision_at_k(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12.2 s, sys: 139 µs, total: 12.2 s\n",
      "Wall time: 12.3 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.15803173"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## *Test Precision*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "test_precision = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "test_precision "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.13703436"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "32086f9b7cc52bc2c8629421cf6cba175094c2e18299455caf64f8eb675094c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}